{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+n9Kjog7RgEFd6F8fQTH/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinayak-Garudi/Machine_Learning/blob/main/Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# two main things to know in ML\n",
        "# Features and labels\n",
        "# here area, location, furnished or not, etc are the features of the house and the rate of the house is the label "
      ],
      "metadata": {
        "id": "PmsHbdZTalLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 parts of ML:\n",
        "# 1. Supervised learning:-\n",
        "#    the data is given and the model works according to it. Eg:- the above example of prediction of rate of the house, is the plant lily or not, etc\n",
        "# 2. Unsupervised learning:-\n",
        "#     no data is given to the model, it categorizes similar features of objects and then take the similar objects in a group.\n",
        "#     Eg:- group of scholar students, grp of avg students, grp of below avg students,etc"
      ],
      "metadata": {
        "id": "Urpp37h-b6jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Testing\n",
        "# the model basically train itself from one set of datas and we can test the model with other set of models.\n",
        "# Eg:- we have 100 datas of house which contains the features and labels. Here we can train the model by giving all the features and labels\n",
        "# of the 1st 50 datas and then test the model for the last 50 datas to predict the labels of the last 50 features"
      ],
      "metadata": {
        "id": "7WubE5nudR3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Linear Regression\n",
        "# it is the method of detting the line which is closest to all the points such that the Mean Squared Error(MSE) is minimum\n",
        "# MSE is the value of the distance between the line of linear regression and the point \n",
        "# lower the value of the MSE or any other error better the will be the model"
      ],
      "metadata": {
        "id": "pBx-06m9eWPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8_TuK_vqpna",
        "outputId": "326f9caf-4743-4a77-be6d-e8625fd854fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error is:  1826.5364191345423\n",
            "Weights:  [  -1.16924976 -237.18461486  518.30606657  309.04865826 -763.14121622\n",
            "  458.90999325   80.62441437  174.32183366  721.49712065   79.19307944]\n",
            "Intercept:  153.05827988224112\n"
          ]
        }
      ],
      "source": [
        "# Linear Regression Code in Python\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "diabetes = datasets.load_diabetes()\n",
        "\n",
        "# print(diabetes.keys())\n",
        "# dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])\n",
        "\n",
        "# print(diabetes.DESCR)\n",
        "\n",
        "diabetes_X = diabetes.data\n",
        "# print(diabetes_X)\n",
        "\n",
        "diabetes_X_train = diabetes_X[:-30]\n",
        "diabetes_X_test = diabetes_X[-30:]\n",
        "\n",
        "diabetes_Y_train = diabetes.target[:-30]\n",
        "diabetes_Y_test = diabetes.target[-30:]\n",
        "\n",
        "model = linear_model.LinearRegression()\n",
        "\n",
        "model.fit(diabetes_X_train, diabetes_Y_train)     \n",
        "\n",
        "diabetes_Y_predicted = model.predict(diabetes_X_test)\n",
        "\n",
        "print(\"Mean squared error is: \", mean_squared_error(diabetes_Y_test, diabetes_Y_predicted))\n",
        "\n",
        "print(\"Weights: \", model.coef_)\n",
        "print(\"Intercept: \", model.intercept_)\n",
        "\n",
        "# plt.scatter(diabetes_X_test, diabetes_Y_test)\n",
        "# plt.plot(diabetes_X_test, diabetes_Y_predicted)\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "# Mean squared error is:  3035.0601152912686\n",
        "# Weights:  [941.43097333]\n",
        "# Intercept:  153.39713623331698\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Functions  and Gradient Descent\n",
        "# loss Functions such as MSE, SSE, Absolute Error\n",
        "# Gradient Descent is equal to x(the value choosen) - Learnning Rate*(dy/dx)\n",
        "# Learning Rate\n",
        "# the rate at which the value will be moving "
      ],
      "metadata": {
        "id": "ZlIzGofLHUPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Descent(GD), Mini Batch Gradient Descent(MGD), Stochastic Gradient Descent(SGD):-\n",
        "# In Gd, the model takes all the data at once for eg we have 1 million if data then it will consider to process all the 1 million data to process\n",
        "# here since it is the huge data it will take a lot of time so it is not feasable to use GD here\n",
        "# To overcome the above problem, MGD is here to save your day!!!\n",
        "# MGD basically takes the data in small groups to process at once for example 100 datas to process at once which helps in saving time\n",
        "# Here in SGD, instead of small group of data, it only takes 1 data at a time to process"
      ],
      "metadata": {
        "id": "K4-PeDmrhoqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supervised Learning: Classification\n",
        "# difference between classification and regression:-\n",
        "# in regression the values/labels will be multiple like the rate of the house is infinite 35 lakhs, 1 crore, 2 crore, etc\n",
        "# whereas in classification the labels will have like yes or no, on or off, 1 or 0, etc. or also classifies that in a group which one is a dog,\n",
        "# on a table of different objects which one is the pencil, etc\n",
        "# in short the labels in regressors can be unlimited whereas in classification the labels are limited"
      ],
      "metadata": {
        "id": "7YIulkVujSPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K Nearest Neighbor Classification\n",
        "\n",
        "from sklearn import datasets \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "print(iris.DESCR)     #DESCR means it give the description of the iris flower\n",
        "\n",
        "features = iris.data\n",
        "labels = iris.target\n",
        "print(features[0], labels[0])\n",
        "# [5.1 3.5 1.4 0.2] 0.... here 0 means Setosa, 1 means Versicolour, 2 means Virginica\n",
        "\n",
        "# Training the classifier\n",
        "clf = KNeighborsClassifier()\n",
        "clf.fit(features, labels)\n",
        "\n",
        "preds = clf.predict([[31, 1, 1, 1]])\n",
        "print(preds)       #... the ans comes 2 that meanes it is Virginica"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2y7UWnlnI3z",
        "outputId": "aea8e901-acb1-4963-fced-aecded80ec2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n",
            "[5.1 3.5 1.4 0.2] 0\n",
            "[2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# About K Nearest Neighbors:-\n",
        "# if we want to find the value of a certain pt on a graph lets take an example of being spam message or not\n",
        "# then we will consider the neighboring pts around it for upto k numbers and then predict whether the pt is a spam msg or not\n",
        "# it higher no of spam pts in the neighbors then it is spam or elese if the neighboring pts are having more not spam pts then is is not spam msgs"
      ],
      "metadata": {
        "id": "C6W_LgUQoIzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression:-  (it is a classifier not a regressor)\n",
        "# it is a classifier that predicts probabilites of the features and then we classify that the modelis good or not..."
      ],
      "metadata": {
        "id": "ELBrmU56zGLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coding Logistic Regression\n",
        "# Train  a logistic regression classifier to predict whether a flower is iris virginica or not\n",
        "# 1 means it is, 0 means it is not\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "iris =  datasets.load_iris()\n",
        "\n",
        "# print(list(iris.keys()))\n",
        "# ['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module']\n",
        "# print(iris['DESCR'])    .... the description about iris\n",
        "\n",
        "X = iris[\"data\"][:, 3:]\n",
        "y = (iris[\"target\"]==2).astype(np.int)\n",
        "\n",
        "# Training a logistic Regression Classifier\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X,y)\n",
        "example = clf.predict(([[1.6]]))      #here 1.6 is a random value which is given by me\n",
        "print(example)     # it will the value 0 that means it is not iris virginica\n",
        "example_1 = clf.predict(([[2.6]]))      #here 2.6 is a random value which is given by me\n",
        "print(example_1)     # it will the value 1 that means it is iris virginica\n",
        "\n",
        "# Using matplotlib to plot the visualization\n",
        "X_new = np.linspace(0,3,1000).reshape(-1,1)\n",
        "#  linspace is used to give the the certain number of values between the range of two numbers\n",
        "# like as in above it will gave 1000 numbers between 0 and 3 including 0 an 3\n",
        "# reshape function gives the values in the desired shape\n",
        "# print(X_new)     #if you want to print those values then uncomment this\n",
        "y_prob = clf.predict_proba(X_new)     #predict_proba predictas the probability\n",
        "plt.plot(X_new,y_prob[:,1])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# print(y)\n",
        "# print(iris[\"data\"])\n",
        "# print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "fwxpdLxk_KMy",
        "outputId": "f22601ef-042a-4a49-dcf4-3c71eb7427d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n",
            "[1]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BwCkH6NenAC2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}